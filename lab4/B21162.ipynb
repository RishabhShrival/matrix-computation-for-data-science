{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "Implementing QR method using gram schmidt method for finding Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_schmidt_algorithm(A):\n",
    "    n = A.shape[1]\n",
    "    result = np.zeros_like(A)\n",
    "\n",
    "    # Orthogonalization\n",
    "    for i in range(n):\n",
    "        result[:, i] = A[:, i]\n",
    "        for j in range(i):\n",
    "            result[:, i] -= ((A[:, i].T @ result[:, j])[0,0] / (result[:, j].T @ result[:, j])[0,0]) * result[:, j]\n",
    "\n",
    "    # Normalization\n",
    "    for i in range(n):\n",
    "        result[:, i] /= np.linalg.norm(result[:, i])\n",
    "\n",
    "    return result\n",
    "\n",
    "def qr_algorithm(A, iterations):\n",
    "    Q_final = np.eye(A.shape[0])\n",
    "\n",
    "    # Iterate 'iterations' times and apply QR operation\n",
    "    for _ in range(iterations):\n",
    "        Q = gram_schmidt_algorithm(A)\n",
    "        R = Q.T @ A\n",
    "        Q_final = Q_final @ Q\n",
    "        A = R @ Q\n",
    "\n",
    "    eigenvalues = np.diag(A)\n",
    "    return eigenvalues, Q_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QR decomposition  Algorithm:  [4.73205081 3.         1.26794919]\n",
      "function:  [1.26794919 3.         4.73205081]\n",
      "Difference:  4.898979485566358\n",
      "\n",
      "QR Eigen-vectors : \n",
      " [[ 0.21132487 -0.57735027  0.78867513]\n",
      " [ 0.57735027 -0.57735027 -0.57735027]\n",
      " [ 0.78867513  0.57735027  0.21132487]]\n",
      "\n",
      "function Eigen-vectors : \n",
      " [[-0.78867513 -0.57735027  0.21132487]\n",
      " [ 0.57735027 -0.57735027  0.57735027]\n",
      " [-0.21132487  0.57735027  0.78867513]]\n"
     ]
    }
   ],
   "source": [
    "A = np.matrix([[2,1,0], [1,3,1], [0,1,4]], dtype=np.float64)\n",
    "# A = np.matrix([[12,-51,4], [6,167,-68], [-4,24,-41]])\n",
    "# A = np.matrix([[4,-2,-1],[-2,4,-2],[1,-2,3]], dtype=np.float64)\n",
    "\n",
    "\n",
    "eig_vals, eig_vecs = qr_algorithm(A, 100)\n",
    "eig_vals_np = np.linalg.eig(A)[0]\n",
    "\n",
    "\n",
    "print(\"QR decomposition  Algorithm: \", eig_vals)\n",
    "print(\"function: \", eig_vals_np)\n",
    "print(\"Difference: \", np.linalg.norm(eig_vals - eig_vals_np))\n",
    "print()\n",
    "print(\"QR Eigen-vectors : \\n\", eig_vecs)\n",
    "print()\n",
    "print(\"function Eigen-vectors : \\n\", np.linalg.eig(A)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that eigen values are approximated nicely. However, the eigenvectors are not the same. it is negative sometimes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2\n",
    "Implementing Cholesky Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cholesky_factorization(A):\n",
    "    if not np.allclose(A, A.T):\n",
    "        raise ValueError(\"Matrix is not symmetric\")\n",
    "    if np.any(np.linalg.eigvals(A) <= 0):\n",
    "        raise ValueError(\"Matrix is not positive definite\")\n",
    "\n",
    "    n = A.shape[0]\n",
    "    L = np.zeros_like(A, dtype=float)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1):\n",
    "            if i == j:\n",
    "                L[i, i] = np.sqrt(A[i, i] - np.sum(L[i, :j]**2))\n",
    "            else:\n",
    "                L[i, j] = (A[i, j] - np.sum(L[i, :j] * L[j, :j])) / L[j, j]\n",
    "    return L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix: \n",
      " [[ 4.   -1.    1.  ]\n",
      " [-1.    4.25  2.75]\n",
      " [ 1.    2.75  3.5 ]]\n",
      "\n",
      "Cholesky Factorization: \n",
      " [[ 2.   0.   0. ]\n",
      " [-0.5  2.   0. ]\n",
      " [ 0.5  1.5  1. ]]\n",
      "\n",
      "L @ L.T: \n",
      " [[ 4.   -1.    1.  ]\n",
      " [-1.    4.25  2.75]\n",
      " [ 1.    2.75  3.5 ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[4, -1, 1], [-1, 4.25, 2.75], [1, 2.75, 3.5]], dtype=np.float64)\n",
    "L = cholesky_factorization(A)\n",
    "print(\"Original Matrix: \\n\", A)\n",
    "print()\n",
    "print(\"Cholesky Factorization: \\n\", L)\n",
    "print()\n",
    "print(\"L @ L.T: \\n\", L @ L.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "# A = np.random.rand(n, n,)\n",
    "L = cholesky_factorization(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3\n",
    "Solving follwing equations\n",
    "\n",
    "6x + 15y + 55z = 76\n",
    "\n",
    "15x + 55y + 225z = 295\n",
    "\n",
    "55x + 225y + 979z = 1259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_substitution(L, b):\n",
    "    n = len(b)\n",
    "    y = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        y[i] = (b[i] - np.dot(L[i, :i], y[:i])) / L[i, i]\n",
    "    return y\n",
    "\n",
    "def backward_substitution(U, y):\n",
    "    n = len(y)\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        x[i] = (y[i] - np.dot(U[i, i+1:], x[i+1:])) / U[i, i]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[6,15,55],\n",
    "              [15,55,225],\n",
    "              [55,225,979]])\n",
    "B = np.array([[76],[295],[1259]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solving Ax = b in 2 steps\n",
    "- L @ y = B\n",
    "- L.T @ x = y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soltion to the system: \n",
      " [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "L = cholesky_factorization(A)\n",
    "y = forward_substitution(L,B)\n",
    "x = backward_substitution(L.T,y)\n",
    "print(\"Soltion to the system: \\n\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.44948974  0.          0.        ]\n",
      " [ 6.12372436  4.18330013  0.        ]\n",
      " [22.45365598 20.91650066  6.11010093]]\n"
     ]
    }
   ],
   "source": [
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.40232400e+03 8.79908000e+03 4.16757300e+04 2.95647600e+05\n",
      " 4.37451000e+01 4.72683000e+01 4.04318867e+01 2.21191920e+01\n",
      " 8.21108000e+01 2.85900400e+01 1.79431900e+02 5.56506000e+02\n",
      " 1.27098500e+03 1.76176330e+04 3.16386400e+00 1.16077000e+01\n",
      " 1.47046627e+01 5.33798700e+00 9.26318200e+00 1.73330950e+00\n",
      " 7.35790000e+03 1.17117500e+04 4.85092000e+04 3.96219200e+05\n",
      " 6.01149200e+01 1.15674190e+02 1.24432971e+02 5.18655810e+01\n",
      " 1.31329600e+02 3.81736600e+01]\n"
     ]
    }
   ],
   "source": [
    "# normalize each feature vector using L1 norm\n",
    "X_train_l1 = X_train / np.linalg.norm(X_train, ord=1, axis=0)\n",
    "X_test_l1 = X_test / np.linalg.norm(X_test, ord=1, axis=0)\n",
    "\n",
    "# normalize each feature vector using L1 norm\n",
    "X_train_l2 = X_train / np.linalg.norm(X_train, ord=2, axis=0)\n",
    "X_test_l2 = X_test / np.linalg.norm(X_test, ord=2, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for original data:  1.8378897999999992\n",
      "Time taken for L1 Normalized data:  0.014183900000006133\n",
      "Time taken for L2 Normalized data:  0.00997389999997722\n"
     ]
    }
   ],
   "source": [
    "# original Data\n",
    "tim = timer()\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "tim_end = timer()\n",
    "print(\"Time taken for original data: \", tim_end - tim)\n",
    "\n",
    "\n",
    "# L1 normalized Data\n",
    "tim = timer()\n",
    "clf_l1 = SVC(kernel='linear')\n",
    "clf_l1.fit(X_train_l1, y_train)\n",
    "y_pred_l1 = clf_l1.predict(X_test_l1)\n",
    "tim_end = timer()\n",
    "print(\"Time taken for L1 Normalized data: \", tim_end - tim)\n",
    "\n",
    "# L2 normalized Data\n",
    "tim = timer()\n",
    "clf_l2 = SVC(kernel='linear')\n",
    "clf_l2.fit(X_train_l2, y_train)\n",
    "y_pred_l2 = clf_l2.predict(X_test_l2)\n",
    "tim_end = timer()\n",
    "print(\"Time taken for L2 Normalized data: \", tim_end - tim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:\n",
      "\tOriginal Data:  0.9736842105263158\n",
      "\tL1 Normalized Data:  0.5789473684210527\n",
      "\tL2 Normalized Data:  0.6929824561403509\n",
      "\n",
      "Precision score:\n",
      "\tOriginal Data:  0.9701492537313433\n",
      "\tL1 Normalized Data:  0.5789473684210527\n",
      "\tL2 Normalized Data:  1.0\n",
      "\n",
      "Recall score:\n",
      "\tOriginal Data:  0.9848484848484849\n",
      "\tL1 Normalized Data:  1.0\n",
      "\tL2 Normalized Data:  0.4696969696969697\n"
     ]
    }
   ],
   "source": [
    "# Acuracy\n",
    "print(\"Accuracy score:\")\n",
    "print(\"\\tOriginal Data: \", accuracy_score(y_test, y_pred))\n",
    "print(\"\\tL1 Normalized Data: \", accuracy_score(y_test, y_pred_l1))\n",
    "print(\"\\tL2 Normalized Data: \", accuracy_score(y_test, y_pred_l2))\n",
    "print()\n",
    "\n",
    "# Precision\n",
    "print(\"Precision score:\")\n",
    "print(\"\\tOriginal Data: \", precision_score(y_test, y_pred,))\n",
    "print(\"\\tL1 Normalized Data: \", precision_score(y_test, y_pred_l1,))\n",
    "print(\"\\tL2 Normalized Data: \", precision_score(y_test, y_pred_l2,))\n",
    "print()\n",
    "\n",
    "# Recall\n",
    "print(\"Recall score:\")\n",
    "print(\"\\tOriginal Data: \", recall_score(y_test, y_pred,))\n",
    "print(\"\\tL1 Normalized Data: \", recall_score(y_test, y_pred_l1,))\n",
    "print(\"\\tL2 Normalized Data: \", recall_score(y_test, y_pred_l2,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Duration\n",
    "Once the data is normalized, the training time was notably reduced, as mentioned earlier. It's almost a 1:100 ratio between normalized and non-normalized data.\n",
    "\n",
    "Accuracy Evaluation\n",
    "We can observe that post normalization, the accuracy score of the model significantly decreased, which is unexpected.\n",
    "\n",
    "Precision Evaluation\n",
    "The precision score of the model decreased after normalization for L1 regularization, but for L2 regularization, it increased to a perfect 1.\n",
    "\n",
    "Recall Evaluation\n",
    "The recall score of the model decreased after normalization for L2 regularization, but for L1 regularization, it increased to a perfect 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
